dist: trusty
sudo: required

# Cache sbt & python downloaded packages
cache:
  directories:
    - $HOME/.sbt
    - $HOME/.local/lib/python3.7
    - $HOME/spark

# Set scala as base language for Spark to be run on the VM
language: scala

# Use docker to run python benchmarks and compare benchmark result files
services:
  - docker

scala:
  - 2.11.12

before_install:
  # if spark is not present, download it and put it in spark's cache directory
  - if [ ! -e $HOME/spark/spark-2.4.1-bin-hadoop2.7 ]; then curl http://apache.mirrors.ovh.net/ftp.apache.org/dist/spark/spark-2.4.1/spark-2.4.1-bin-hadoop2.7.tgz > $HOME/spark.tgz && tar -C $HOME/spark -xf $HOME/spark.tgz; fi
  - docker pull python:3.7

script: "./run-tests.sh"

# Send notifs to slack
notifications:
  slack:
    secure: "TeoxLj02yGhZqKEO4lDpQJZsaepoyyFf6mI0EZRJv3HCXZ85E5oNrw27L1DeXIbM4ap/pgdzBlfgzVPMPN3bI5G+th4MAvs7QbxfoBAtWUoQxet4xO/WPXfemlMOFONicre7T5lLy5c7HLB05jzo972j89nKuPPiqVboHLQQ5X37oCeDEn983l+lHzwMxn2DbnWyoqVSKih7bXBbHWXNnURXZXmsUA9ZDNnQCj3UpRSNhi67SnXAl5c/2Xk8neY0kpsW3hiTfE2IX5yiut4G+jiNioJxYUKSA2+fyq9N2+IT1ynmXOmYm/WXFNch6zHk4XztTOBeL9VInKo8SEvUqLqu461FAYWeyfV/bAN5HmgFfipePK/Ip+p9dL4bAseJr8TJ8lAr2j2dmvoBQezCOfml403a+Fwh8BGROwUC7g66aPZ+bdr+X34JUgeS4yJKSTsy+G6xqIeBUzAAciVSsAtCT6UFbe7wpIk05X+/Qfzp79FkkvzVmvhn36d3tc9kfhGrbOLnfx6gD0j+4F8S5Klq/RcYRFDLjz5T8oebRjYhCc0AtjJrpZ3eTv/fpj+w4cx4UaWboMByniFguQycInbSpBJo9bUm8b4BcTnTigw5zE2ukxAL3+AskvXrE4GWY+n+PLuH0wwgeTIND6ljnnCYrH2hvl0zjtwm2shLCrc="
